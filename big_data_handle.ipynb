{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# For a single node opeartion, we can use Polars lazy API to read larger than memory datasets using streaming\n",
    "\n",
    "# Read the Parquet file using lazy evaluation\n",
    "df = pl.scan_parquet('large_dataset.parquet')\n",
    "\n",
    "# Melt the DataFrame to have 'year' and 'weight' columns\n",
    "df_unpivot = df.unpivot(\n",
    "    index='patient',\n",
    "    on=[col for col in df.collect_schema().names() if col != 'patient'],\n",
    "    variable_name='year',\n",
    "    value_name='weight'\n",
    ")\n",
    "\n",
    "# Compute statistical metrics for each patient\n",
    "stats_df = df_unpivot.group_by('patient').agg([\n",
    "    pl.col('weight').mean().alias('mean_weight'),\n",
    "    pl.col('weight').median().alias('median_weight'),\n",
    "    pl.col('weight').std().alias('std_weight'),\n",
    "    pl.col('weight').min().alias('min_weight'),\n",
    "    pl.col('weight').max().alias('max_weight'),\n",
    "    pl.col('weight').quantile(0.25).alias('q1_weight'),\n",
    "    pl.col('weight').quantile(0.75).alias('q3_weight')\n",
    "])\n",
    "\n",
    "# Collect the result into a DataFrame\n",
    "stats_df_result = stats_df.collect()\n",
    "\n",
    "# Save the result to a CSV file\n",
    "stats_df_result.write_csv('person_statistics.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# For a single node opeartion, we can use Polars lazy API to read larger than memory datasets using streaming\n",
    "\n",
    "# Read the Parquet file using lazy evaluation\n",
    "df = pl.scan_parquet('large_dataset.parquet')\n",
    "\n",
    "# Melt the DataFrame to have 'year' and 'weight' columns\n",
    "df_unpivot = df.unpivot(\n",
    "    index='patient',\n",
    "    on=[col for col in df.collect_schema().names() if col != 'patient'],\n",
    "    variable_name='year',\n",
    "    value_name='weight'\n",
    ")\n",
    "\n",
    "# Compute statistical metrics for each patient\n",
    "stats_df = df_unpivot.group_by('year').agg([\n",
    "    pl.col('weight').mean().alias('mean_weight'),\n",
    "    pl.col('weight').median().alias('median_weight'),\n",
    "    pl.col('weight').std().alias('std_weight'),\n",
    "    pl.col('weight').min().alias('min_weight'),\n",
    "    pl.col('weight').max().alias('max_weight'),\n",
    "    pl.col('weight').quantile(0.25).alias('q1_weight'),\n",
    "    pl.col('weight').quantile(0.75).alias('q3_weight')\n",
    "])\n",
    "\n",
    "# Collect the result into a DataFrame\n",
    "stats_df_result = stats_df.collect()\n",
    "\n",
    "# Save the result to a CSV file\n",
    "stats_df_result.write_csv('year_statistics.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# For a single node opeartion, we can use Polars lazy API to read larger than memory datasets using streaming\n",
    "\n",
    "# Read the Parquet file using lazy evaluation\n",
    "df = pl.scan_parquet('large_dataset.parquet')\n",
    "\n",
    "# Melt the DataFrame to have 'year' and 'weight' columns\n",
    "df_unpivot = df.unpivot(\n",
    "    index='patient',\n",
    "    on=[col for col in df.collect_schema().names() if col != 'patient'],\n",
    "    variable_name='year',\n",
    "    value_name='weight'\n",
    ")\n",
    "\n",
    "# Convert 'year' to integer\n",
    "df_unpivot = df_unpivot.with_columns(pl.col('year').str.extract(r'(\\d+)$').cast(pl.Int32))\n",
    "\n",
    "# Sort by 'patient' and 'year' to ensure correct order\n",
    "df_unpivot = df_unpivot.sort(['patient', 'year'])\n",
    "\n",
    "# Calculate the weight difference per patient between consecutive years\n",
    "df_diff = df_unpivot.with_columns([\n",
    "    (pl.col('weight') - pl.col('weight').shift(1)).alias('weight_change'),\n",
    "    pl.col('patient').eq(pl.col('patient').shift(1)).alias('same_patient')\n",
    "]).filter(pl.col('same_patient'))\n",
    "\n",
    "# Group by 'year' and calculate average weight change\n",
    "weight_trends = df_diff.group_by('year').agg([\n",
    "    pl.col('weight_change').mean().alias('avg_weight_change')\n",
    "])\n",
    "\n",
    "# Collect the result into a DataFrame\n",
    "weight_trends_result = weight_trends.collect()\n",
    "\n",
    "# Save the result to a CSV file\n",
    "weight_trends_result.write_csv('weight_trends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (119, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>avg_weight_change</th></tr><tr><td>i32</td><td>f64</td></tr></thead><tbody><tr><td>1977</td><td>0.90178</td></tr><tr><td>1989</td><td>-0.22679</td></tr><tr><td>1986</td><td>-0.53195</td></tr><tr><td>1974</td><td>-0.84213</td></tr><tr><td>1980</td><td>-0.91579</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1947</td><td>-0.07116</td></tr><tr><td>1953</td><td>0.13595</td></tr><tr><td>1962</td><td>0.80743</td></tr><tr><td>1956</td><td>-0.6312</td></tr><tr><td>1950</td><td>-0.8589</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (119, 2)\n",
       "┌──────┬───────────────────┐\n",
       "│ year ┆ avg_weight_change │\n",
       "│ ---  ┆ ---               │\n",
       "│ i32  ┆ f64               │\n",
       "╞══════╪═══════════════════╡\n",
       "│ 1977 ┆ 0.90178           │\n",
       "│ 1989 ┆ -0.22679          │\n",
       "│ 1986 ┆ -0.53195          │\n",
       "│ 1974 ┆ -0.84213          │\n",
       "│ 1980 ┆ -0.91579          │\n",
       "│ …    ┆ …                 │\n",
       "│ 1947 ┆ -0.07116          │\n",
       "│ 1953 ┆ 0.13595           │\n",
       "│ 1962 ┆ 0.80743           │\n",
       "│ 1956 ┆ -0.6312           │\n",
       "│ 1950 ┆ -0.8589           │\n",
       "└──────┴───────────────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_trends.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
